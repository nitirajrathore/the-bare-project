# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=

TRACELOOP_API_KEY=""


MODEL_PROVIDER=openai
MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-large
OPENAI_API_KEY=''


# MODEL_PROVIDER=ollama
# MODEL='llama3.1'
# EMBEDDING_MODEL='llama3.1'
# OLLAMA_HOST=http://213.180.0.35:47950


# MODEL_PROVIDER='google'
# MODEL='gemini-1.5-flash-001'
# EMBEDDING_MODEL='text-embedding-004'
# GOOGLE_API_KEY=''



# MODEL_PROVIDER='mock'
# MODEL='mock'
# EMBEDDING_MODEL='mock'
# MOCK_RESPONSES='mock_responses.json'





# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=


# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
# TOP_K=

# The directory to store the local storage cache.
STORAGE_CACHE_DIR=.cache

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# The API for the chat endpoint. Set when using a custom backend (e.g. Express). Use full URL like http://localhost:8000/api/chat
# NEXT_PUBLIC_CHAT_API=

# Customize prompt to generate the next question suggestions based on the conversation history.
# Disable this prompt to disable the next question suggestions feature.
NEXT_QUESTION_PROMPT="You're a helpful assistant! Your task is to suggest the next question that user might ask. 
Here is the conversation history
---------------------
{conversation}
---------------------
Given the conversation history, please give me 3 questions that user might ask next!
Your answer should be wrapped in three sticks which follows the following format:
```
<question 1>
<question 2>
<question 3>
```"

# The system prompt for the AI model.
SYSTEM_PROMPT="You are a helpful assistant who helps users with their questions.
You have access to a knowledge base including the facts that you should start with to find the answer for the user question. Use the query engine tool to retrieve the facts from the knowledge base."



OTEL_EXPORTER_OTLP_HEADERS="api_key=84a48dfbfa6aedaa645:274a608"
PHOENIX_CLIENT_HEADERS="api_key=84a48dfbfa6aedaa645:274a608"
PHOENIX_COLLECTOR_ENDPOINT="https://app.phoenix.arize.com"
PHOENIX_HOST="https://app.phoenix.arize.com"
